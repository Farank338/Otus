{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мини-поисковик по базе текстов\n",
    "\n",
    "План работы прост\n",
    "Скачать текста\n",
    "Проиндексировать\n",
    "Поисковик по индексам\n",
    "\n",
    "Для скачивания возьмем несколько классических произведений, война и мир 4 тома"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw=[\n",
    "    'http://az.lib.ru/t/tolstoj_lew_nikolaewich/text_0040.shtml',\n",
    "    'http://az.lib.ru/t/tolstoj_lew_nikolaewich/text_0050.shtml',\n",
    "    'http://az.lib.ru/t/tolstoj_lew_nikolaewich/text_0060.shtml',\n",
    "    'http://az.lib.ru/t/tolstoj_lew_nikolaewich/text_0070.shtml'\n",
    "]\n",
    "\n",
    "import hashlib\n",
    "hash_raw={}\n",
    "for i in raw:\n",
    "    hash_object = hashlib.md5(i.encode())\n",
    "    hash_raw[hash_object.hexdigest()]=i\n",
    "\n",
    "import requests\n",
    "for i in hash_raw:\n",
    "    url=hash_raw[i]\n",
    "    r = requests.get(url)\n",
    "    text=r.content.decode(encoding='cp1251', errors=\"ignore\")\n",
    "    with open('raw/'+i+'.html', \"w\") as text_file:\n",
    "        text_file.write(text)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачав текста можно заняться индексацией, будет индексировать максимально просто по словам которые больше 2х символов\n",
    "Убрав все спец символы перед этим "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "hash_words={}\n",
    "for i in hash_raw:\n",
    "    with open('raw/'+i+'.html', \"r\") as text_file:\n",
    "        text=text_file.read()\n",
    "        text=re.sub('[^0-9a-zA-Zа-яА-Я]',' ',text)\n",
    "        words=text.split()\n",
    "        words_hash={}\n",
    "        for j in words:\n",
    "            if len(j)<2:continue\n",
    "            if j in words_hash:\n",
    "                words_hash[j]=words_hash[j]+1\n",
    "            else:\n",
    "                words_hash[j]=1\n",
    "        hash_words[i]=words_hash\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получив списко слов и число их вхождений теперь нужно сохранить их в какую либо структуру где не страница будет вести к слову а слово к странице\n",
    "Дерево из хеш мап выглядит как вполне подходящее для этих целей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Index:\n",
    "    def __init__(self):\n",
    "        self.tree={}\n",
    "        self.words={}\n",
    "    \n",
    "\n",
    "    def insert(self,word:str,data):\n",
    "        if len(word)>1:\n",
    "            char=word[0]\n",
    "            if char not in self.tree:\n",
    "                self.tree[char]=Index()\n",
    "            self.tree[char].insert(word[1:],data)\n",
    "            return\n",
    "        \n",
    "        if word in self.words:\n",
    "            self.words[word]=self.words[word]+data\n",
    "        else:\n",
    "            self.words[word]=data\n",
    "        return\n",
    "    \n",
    "    def search(self,word):\n",
    "        if len(word)>1:\n",
    "            char=word[0]\n",
    "            if char not in self.tree:\n",
    "                return None\n",
    "            return self.tree[char].search(word[1:])\n",
    "        if word in self.words:\n",
    "            return self.words[word]\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=Index()\n",
    "for i in hash_words:\n",
    "    for j in hash_words[i]:\n",
    "        index.insert(j,[i,hash_words[i][j]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь имя на руках индексы всех вхождений кажого слова и того куда и в каком количестве они входят нужна функция поисковика, которая сможет объеденить результаты по множеству слов котоыре подаются на вход поисковой функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(hash_raw,index,to_search:str, true_to_or:bool=True):\n",
    "    text=re.sub('[^0-9a-zA-Zа-яА-Я]',' ',to_search)\n",
    "    words=text.split()\n",
    "\n",
    "    results=[]\n",
    "    for i in words:\n",
    "        res=index.search(i)\n",
    "        if res is None and true_to_or is False:return []\n",
    "        if res is None: continue\n",
    "        results.append(res)\n",
    "    results_all=[]\n",
    "    results_all_uniq={}\n",
    "    if true_to_or is True:\n",
    "        \n",
    "        for i in results:\n",
    "            for j in range(0,len(i),2):\n",
    "                results_all.append([i[j],i[j+1]])\n",
    "        \n",
    "        results_all_uniq={}\n",
    "        for i in results_all:\n",
    "            if i[0] in results_all_uniq:\n",
    "                results_all_uniq[i[0]]=results_all_uniq[i[0]]+i[1]\n",
    "            else:\n",
    "                results_all_uniq[i[0]]=i[1]\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        results_all_uniq={}\n",
    "        first=True\n",
    "        for i in results:\n",
    "            this_result={}\n",
    "            for j in range(0,len(i),2):\n",
    "                key=i[j]\n",
    "                value=i[j+1]\n",
    "\n",
    "                if first is True:\n",
    "                    results_all_uniq[key]=value\n",
    "                else:\n",
    "                    this_result[key]=value\n",
    "            \n",
    "            \n",
    "            if first is True:\n",
    "                first=False\n",
    "            else:\n",
    "                for k in this_result:\n",
    "                    if k in results_all_uniq:\n",
    "                        results_all_uniq[k]=results_all_uniq[k]+this_result[k]\n",
    "                to_drop=[]\n",
    "                for k in results_all_uniq:\n",
    "                    if k not in this_result:\n",
    "                        to_drop.append(k)\n",
    "                for j in to_drop:\n",
    "                    results_all_uniq.pop(j)       \n",
    "    results_all=[]\n",
    "    for k in results_all_uniq: \n",
    "        results_all.append([k,results_all_uniq[k]])\n",
    "    results_all.sort(key = lambda x: x[1],reverse=True)\n",
    "\n",
    "    for i in results_all:\n",
    "        i[0]=hash_raw[i[0]]\n",
    "    return results_all\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://az.lib.ru/t/tolstoj_lew_nikolaewich/text_0060.shtml', 2393]\n",
      "['http://az.lib.ru/t/tolstoj_lew_nikolaewich/text_0070.shtml', 2269]\n",
      "['http://az.lib.ru/t/tolstoj_lew_nikolaewich/text_0050.shtml', 2172]\n",
      "['http://az.lib.ru/t/tolstoj_lew_nikolaewich/text_0040.shtml', 1778]\n"
     ]
    }
   ],
   "source": [
    "result=search(hash_raw,index,'что или ',False)\n",
    "for i in result:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
